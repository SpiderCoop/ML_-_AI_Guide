{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Árboles de Decisión\n",
    "\n",
    "Los **árboles de decisión** son modelos predictivos utilizados tanto en problemas de clasificación como de regresión. Estos modelos se basan en una estructura de árbol, donde cada nodo representa una característica o atributo del conjunto de datos, y cada rama representa un valor posible de ese atributo. Las hojas del árbol representan las predicciones finales o la salida del modelo.\n",
    "\n",
    "## Estructura de un Árbol de Decisión\n",
    "\n",
    "Un árbol de decisión está compuesto por tres elementos clave:\n",
    "\n",
    "1. **Nodos de Decisión (nodos internos):** Representan una prueba o condición sobre un atributo. \n",
    "2. **Ramas:** Conectan los nodos y representan el resultado de una prueba o condición.\n",
    "3. **Nodos Hoja (nodos terminales):** Representan la decisión o predicción final, que puede ser una clase (en clasificación) o un valor continuo (en regresión).\n",
    "\n",
    "El árbol se construye mediante un proceso de particionamiento recursivo. Comienza en la raíz y se realizan divisiones sucesivas de los datos en subconjuntos más pequeños, utilizando el atributo que mejor separa los datos según un criterio de división. Este proceso continúa hasta que se cumple un criterio de parada, como la profundidad máxima del árbol o un número mínimo de muestras en un nodo.\n",
    "\n",
    "### Criterios de División\n",
    "\n",
    "Los criterios de división determinan cómo se eligen los atributos en cada nodo para dividir los datos:\n",
    "\n",
    "1. **Índice de Gini:** Mide la pureza de los nodos. Un nodo es puro si contiene solo muestras de una clase. El índice de Gini se utiliza comúnmente en clasificación.\n",
    "   \n",
    "   $\n",
    "   Gini = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "   $\n",
    "   donde $p_i$ es la proporción de elementos en la clase $i$.\n",
    "\n",
    "2. **Entropía:** Mide la incertidumbre o impureza en un nodo. Es utilizada en la construcción de árboles de decisión como el algoritmo ID3.\n",
    "   \n",
    "   $\n",
    "   Entropía = - \\sum_{i=1}^{n} p_i \\log_2(p_i)\n",
    "   $\n",
    "    donde $p_i$ es la proporción de elementos en la clase $i$.\n",
    "\n",
    "3. **Reducción de Varianza (para regresión):** En problemas de regresión, se utiliza la varianza de las muestras en los nodos para decidir las divisiones. Se elige la partición que minimiza la varianza dentro de los nodos hijos.\n",
    "\n",
    "### Ecuación del Modelo\n",
    "\n",
    "La predicción para un árbol de decisión en un problema de clasificación se puede representar como:\n",
    "\n",
    "$\n",
    "\\hat{y} = \\text{Clase más frecuente en la hoja correspondiente a los valores de } x_1, x_2, \\ldots, x_n\n",
    "$\n",
    "\n",
    "Para un problema de regresión, la predicción se obtiene promediando los valores de las muestras en la hoja:\n",
    "\n",
    "$\n",
    "\\hat{y} = \\frac{1}{m} \\sum_{i=1}^{m} y_i\n",
    "$\n",
    "donde $m$ es el número de muestras en la hoja, y $y_i$ es el valor de la variable dependiente.\n",
    "\n",
    "## Ventajas y Desventajas\n",
    "\n",
    "- **Ventajas:**\n",
    "- **Interpretabilidad:** Los árboles de decisión son fáciles de entender y visualizar.\n",
    "- **No linealidad:** Capturan relaciones no lineales entre las variables independientes y la variable dependiente.\n",
    "- **No requieren normalización:** No es necesario escalar las características, y pueden manejar variables categóricas y continuas.\n",
    "\n",
    "- **Desventajas:**\n",
    "- **Sobreajuste:** Los árboles de decisión pueden sobreajustarse fácilmente a los datos de entrenamiento, lo que reduce su capacidad de generalización.\n",
    "- **Inestabilidad:** Pequeñas variaciones en los datos pueden llevar a cambios significativos en la estructura del árbol.\n",
    "\n",
    "## Ejemplo de Aplicación\n",
    "\n",
    "Supongamos que queremos predecir si un cliente comprará un producto en función de sus características demográficas (edad, ingreso, etc.).\n",
    "\n",
    "- **Datos de ejemplo:**\n",
    "  \n",
    "  | Edad | Ingreso | Compra |\n",
    "  |------|---------|--------|\n",
    "  | 25   | Bajo    | No     |\n",
    "  | 35   | Alto    | Sí     |\n",
    "  | 45   | Medio   | Sí     |\n",
    "  | 50   | Alto    | No     |\n",
    "\n",
    "- **Construcción del Árbol:**\n",
    "  Utilizando un algoritmo como CART (Classification and Regression Tree), el árbol se construye seleccionando la característica (Edad o Ingreso) que mejor divide los datos según un criterio como el índice de Gini o la entropía. El proceso continúa hasta que se cumplen las condiciones de parada.\n",
    "\n",
    "- **Predicción:**\n",
    "  Para un nuevo cliente de 40 años con ingreso medio, el árbol de decisión determinará si comprará o no en función de las reglas aprendidas en los nodos.\n",
    "\n",
    "### Implementación en Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción para el nuevo cliente: Sí\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([\n",
    "    [25, 'Bajo'], \n",
    "    [35, 'Alto'], \n",
    "    [45, 'Medio'], \n",
    "    [50, 'Alto']\n",
    "])\n",
    "y = np.array(['No', 'Sí', 'Sí', 'No'])\n",
    "\n",
    "# Convertir la columna categórica ('Bajo', 'Alto', 'Medio') en valores numéricos\n",
    "le = LabelEncoder()\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# Convertir X de nuevo a tipo numérico (entero)\n",
    "X = X.astype(float)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "model = DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predicción para un nuevo cliente\n",
    "nuevo_cliente = np.array([[40, 'Medio']])\n",
    "\n",
    "# Convertir la característica categórica del nuevo cliente\n",
    "nuevo_cliente[:, 1] = le.transform(nuevo_cliente[:, 1])\n",
    "\n",
    "# Convertir nuevo_cliente a tipo numérico (entero)\n",
    "nuevo_cliente = nuevo_cliente.astype(float)\n",
    "\n",
    "# Realizar la predicción\n",
    "prediccion = model.predict(nuevo_cliente)\n",
    "\n",
    "print(f'Predicción para el nuevo cliente: {prediccion[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
