{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de optimización\n",
    "\n",
    "Existen diferentes metodos de optimizacion para estimar los parámetros o coeficientes de los diferentes modelos de aprendizaje de maquina. Cada uno tiene ventajas y desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mínimos Cuadrados Ordinarios\n",
    "\n",
    "El método de mínimos cuadrados ordinarios (OLS, por sus siglas en inglés) es una técnica estadística ampliamente utilizada para estimar los parámetros de un modelo de regresión lineal. El objetivo principal de OLS es encontrar la línea que mejor se ajuste a un conjunto de datos, minimizando la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.\n",
    "\n",
    "#### Ecuación del Modelo\n",
    "\n",
    "Para un modelo de regresión lineal simple, la ecuación es:\n",
    "\n",
    "$ y = \\beta_0 + \\beta_1 x + \\epsilon $\n",
    "\n",
    "donde:\n",
    "- $y$ es la variable dependiente.\n",
    "- $x$ es la variable independiente.\n",
    "- $\\beta_0$ es la intersección con el eje $y$ (constante o término independiente).\n",
    "- $\\beta_1$ es la pendiente de la línea de regresión.\n",
    "- $\\epsilon$ es el término de error.\n",
    "\n",
    "#### Objetivo de OLS\n",
    "\n",
    "El objetivo de OLS es estimar los parámetros $\\beta_0$ y $\\beta_1$ que minimicen la suma de los cuadrados de los residuos (errores), definidos como las diferencias entre los valores observados ($y_i$) y los valores predichos ($\\hat{y_i}$) por el modelo:\n",
    "\n",
    "$ \\text{Suma de Cuadrados de los Errores (SSE)} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $\n",
    "\n",
    "donde:\n",
    "- $n$ es el número de observaciones.\n",
    "- $y_i$ son los valores observados.\n",
    "- $\\hat{y_i} = \\beta_0 + \\beta_1 x_i$ son los valores predichos.\n",
    "\n",
    "#### Proceso de Estimación\n",
    "\n",
    "Los parámetros $\\beta_0$ y $\\beta_1$ se estiman resolviendo las siguientes ecuaciones normales:\n",
    "\n",
    "$ \\beta_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $\n",
    "\n",
    "$ \\beta_0 = \\bar{y} - \\beta_1 \\bar{x} $\n",
    "\n",
    "donde:\n",
    "- $\\bar{x}$ es el valor promedio de $x$.\n",
    "- $\\bar{y}$ es el valor promedio de $y$.\n",
    "\n",
    "#### Interpretación de los Parámetros\n",
    "\n",
    "- **$\\beta_0$ (intersección):** Representa el valor esperado de $y$ cuando $x$ es 0.\n",
    "- **$\\beta_1$ (pendiente):** Indica el cambio esperado en $y$ por cada unidad adicional de $x$.\n",
    "\n",
    "#### Suposiciones de OLS\n",
    "\n",
    "Para que las estimaciones obtenidas mediante OLS sean válidas, deben cumplirse ciertas suposiciones:\n",
    "1. **Linealidad:** La relación entre la variable dependiente y la variable independiente es lineal.\n",
    "2. **Independencia:** Las observaciones son independientes entre sí.\n",
    "3. **Homoscedasticidad:** La variabilidad de los errores es constante a lo largo de todos los valores de la variable independiente.\n",
    "4. **Normalidad de los Errores:** Los errores de la regresión son distribuidos normalmente.\n",
    "5. **No Multicolinealidad (para regresión múltiple):** Las variables independientes no están altamente correlacionadas entre sí.\n",
    "\n",
    "#### Ventajas de OLS\n",
    "\n",
    "- **Simplicidad:** Es fácil de entender e implementar.\n",
    "- **Interpretabilidad:** Los parámetros tienen una interpretación clara.\n",
    "- **Eficiencia:** Si las suposiciones se cumplen, OLS produce estimadores que son insesgados y eficientes (con la menor varianza posible).\n",
    "\n",
    "#### Limitaciones de OLS\n",
    "\n",
    "- **Sensibilidad a Valores Atípicos:** Los outliers pueden tener un gran impacto en los estimadores.\n",
    "- **Suposiciones Estrictas:** Las suposiciones deben cumplirse para que los resultados sean válidos.\n",
    "- **No Captura Relaciones No Lineales:** OLS solo es adecuado para relaciones lineales.\n",
    "\n",
    "#### Ejemplo de Aplicación en Python\n",
    "\n",
    "A continuación, se muestra cómo implementar el método OLS en Python usando la librería `statsmodels`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Agregar una constante (intersección)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Ajustar el modelo OLS\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente\n",
    "\n",
    "#### Descripción\n",
    "El gradiente descendente es un algoritmo iterativo utilizado para minimizar funciones de costo. Es particularmente útil en machine learning para encontrar los parámetros óptimos del modelo.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Inicialización:** Asignar valores iniciales a los parámetros $\\theta$.\n",
    "2. **Cálculo del Gradiente:** Calcular el gradiente de la función de costo $J(\\theta)$ con respecto a cada parámetro.\n",
    "   $\\nabla J(\\theta) = \\left[ \\frac{\\partial J(\\theta)}{\\partial \\theta_1}, \\frac{\\partial J(\\theta)}{\\partial \\theta_2}, \\ldots, \\frac{\\partial J(\\theta)}{\\partial \\theta_n} \\right]$\n",
    "3. **Actualización de Parámetros:** Actualizar los parámetros en la dirección del gradiente negativo.\n",
    "   $\\theta := \\theta - \\alpha \\nabla J(\\theta)$\n",
    "   donde $\\alpha$ es la tasa de aprendizaje.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros $\\theta$ representan los coeficientes que definen el modelo. La actualización iterativa ajusta estos coeficientes para minimizar la función de costo.\n",
    "\n",
    "#### Suposiciones\n",
    "1. La función de costo es diferenciable.\n",
    "2. La tasa de aprendizaje es adecuadamente escogida para garantizar la convergencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "# Inicialización\n",
    "theta = 0\n",
    "alpha = 0.01  # Tasa de aprendizaje\n",
    "iterations = 1000\n",
    "\n",
    "# Función de costo\n",
    "def cost_function(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X * theta\n",
    "    return (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
    "\n",
    "# Gradiente descendente\n",
    "for _ in range(iterations):\n",
    "    gradient = (1 / len(y)) * np.sum(X * (X * theta - y))\n",
    "    theta -= alpha * gradient\n",
    "\n",
    "print(f\"Parámetro optimizado: {theta}\")\n",
    "print(f\"Costo final: {cost_function(X, y, theta)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente Estocástico (SGD)\n",
    "\n",
    "#### Descripción\n",
    "El gradiente descendente estocástico es una variante del gradiente descendente que actualiza los parámetros del modelo después de cada muestra individual.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Inicialización:** Asignar valores iniciales a los parámetros $\\theta$.\n",
    "2. **Iteración sobre los Datos:** Para cada muestra $i$ en el conjunto de datos:\n",
    "   $\\theta := \\theta - \\alpha \\nabla J(\\theta; x^{(i)}, y^{(i)})$\n",
    "   donde $\\nabla J(\\theta; x^{(i)}, y^{(i)})$ es el gradiente de la función de costo para la muestra $i$.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros $\\theta$ se ajustan después de cada muestra, lo que puede conducir a convergencia más rápida en grandes conjuntos de datos.\n",
    "\n",
    "#### Suposiciones\n",
    "1. Las observaciones son independientes.\n",
    "2. La función de costo es diferenciable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "# Inicialización\n",
    "theta = 0\n",
    "alpha = 0.01  # Tasa de aprendizaje\n",
    "epochs = 1000\n",
    "\n",
    "# Gradiente descendente estocástico\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(y)):\n",
    "        gradient = X[i] * (X[i] * theta - y[i])\n",
    "        theta -= alpha * gradient\n",
    "\n",
    "print(f\"Parámetro optimizado: {theta}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización (Ridge y Lasso)\n",
    "\n",
    "#### Descripción\n",
    "La regularización agrega un término de penalización a la función de costo para evitar el sobreajuste y mejorar la generalización del modelo.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "- **Ridge Regression (L2 Regularization):**\n",
    "  $\\text{Costo} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2$\n",
    "- **Lasso Regression (L1 Regularization):**\n",
    "  $\\text{Costo} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|$\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- En Ridge, los parámetros $\\beta$ se contraen hacia cero pero no pueden ser exactamente cero.\n",
    "- En Lasso, algunos parámetros $\\beta$ pueden ser exactamente cero, lo que realiza selección de características.\n",
    "\n",
    "#### Suposiciones\n",
    "1. La relación entre las variables independientes y la variable dependiente es lineal.\n",
    "2. Las observaciones son independientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "# Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X, y)\n",
    "print(f\"Parámetros Ridge: {ridge.coef_}, Intersección: {ridge.intercept_}\")\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X, y)\n",
    "print(f\"Parámetros Lasso: {lasso.coef_}, Intersección: {lasso.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de Máxima Verosimilitud\n",
    "\n",
    "#### Descripción\n",
    "Este método busca los parámetros que maximizan la probabilidad de observar los datos dados el modelo.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Función de Verosimilitud:**\n",
    "   $L(\\theta) = P(\\text{datos}|\\theta)$\n",
    "2. **Log-Verosimilitud:**\n",
    "   $\\log L(\\theta) = \\sum_{i=1}^{n} \\log P(y_i|\\theta)$\n",
    "3. **Maximización:**\n",
    "   $\\hat{\\theta} = \\arg\\max_{\\theta} \\log L(\\theta)$\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros $\\theta$ se eligen para maximizar la probabilidad de los datos observados.\n",
    "\n",
    "#### Suposiciones\n",
    "1. El modelo probabilístico especificado es correcto.\n",
    "2. Las observaciones son independientes y identicamente distribuidas (i.i.d.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "# Función de verosimilitud negativa\n",
    "def negative_log_likelihood(params):\n",
    "    theta = params[0]\n",
    "    predictions = X * theta\n",
    "    residuals = y - predictions\n",
    "    nll = np.sum(residuals**2)\n",
    "    return nll\n",
    "\n",
    "# Optimización\n",
    "result = minimize(negative_log_likelihood, [0])\n",
    "theta_opt = result.x[0]\n",
    "\n",
    "print(f\"Parámetro optimizado: {theta_opt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Expectation-Maximization (EM)\n",
    "\n",
    "#### Descripción\n",
    "Es un método iterativo para encontrar los parámetros máximos de verosimilitud en modelos con variables latentes.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Expectation Step (E-step):** Calcula la expectativa de la función de verosimilitud completa.\n",
    "2. **Maximization Step (M-step):** Maximiza la función de verosimilitud basada en la expectativa calculada en la E-step.\n",
    "3. **Iteración:** Repite los pasos anteriores hasta la convergencia.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros se estiman para maximizar la verosimilitud esperada de los datos observados y las variables latentes.\n",
    "\n",
    "#### Suposiciones\n",
    "1. Las distribuciones de las variables observadas y latentes son conocidas.\n",
    "2. El modelo especificado es correcto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "\n",
    "# Modelo de mezcla gaussiana (EM)\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(X)\n",
    "\n",
    "print(f\"Medias: {gmm.means_.flatten()}\")\n",
    "print(f\"Varianzas: {gmm.covariances_.flatten()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Levenberg-Marquardt\n",
    "\n",
    "#### Descripción\n",
    "Combina el gradiente descendente y el método de Newton para minimizar la función de error en problemas de ajuste no lineal.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Actualizar los Parámetros:**\n",
    "   $\\theta := \\theta - (J^T J + \\lambda I)^{-1} J^T \\mathbf{e}$\n",
    "   donde $J$ es la matriz jacobiana, $\\mathbf{e}$ es el vector de errores, y $\\lambda$ es un parámetro de regularización.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros $\\theta$ se ajustan iterativamente para minimizar la función de error, con un equilibrio entre el gradiente descendente y la actualización de Newton.\n",
    "\n",
    "#### Suposiciones\n",
    "1. La función de error es diferenciable.\n",
    "2. La matriz jacobiana $J$ es bien condicionada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 3, 2, 3, 5])\n",
    "\n",
    "# Función de error\n",
    "def residuals(theta, X, y):\n",
    "    return X * theta - y\n",
    "\n",
    "# Optimización\n",
    "result = least_squares(residuals, 0, args=(X, y))\n",
    "theta_opt = result.x[0]\n",
    "\n",
    "print(f\"Parámetro optimizado: {theta_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización Bayesiana\n",
    "\n",
    "#### Descripción\n",
    "Utiliza modelos probabilísticos para buscar el mínimo global de una función. Es especialmente útil cuando las evaluaciones de la función objetivo son costosas.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Modelo Probabilístico:** Construir un modelo probabilístico de la función objetivo, como un proceso gaussiano.\n",
    "2. **Función de Adquisición:** Maximizar una función de adquisición que equilibra exploración y explotación.\n",
    "3. **Actualización:** Actualizar el modelo probabilístico con los nuevos puntos de datos obtenidos.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros del modelo probabilístico se ajustan para mejorar la precisión de las predicciones y guiar la búsqueda del mínimo global.\n",
    "\n",
    "#### Suposiciones\n",
    "1. La función objetivo es costosa de evaluar.\n",
    "2. Se dispone de un modelo probabilístico adecuado para la función objetivo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "# Función objetivo\n",
    "def objective(x):\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# Optimización bayesiana\n",
    "result = gp_minimize(objective, [(-5.0, 5.0)], n_calls=30, random_state=42)\n",
    "x_opt = result.x[0]\n",
    "\n",
    "print(f\"Parámetro optimizado: {x_opt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos Evolutivos\n",
    "\n",
    "#### Descripción\n",
    "Basados en principios de la evolución natural, estos métodos optimizan una función mediante la simulación de procesos como la selección, mutación y recombinación.\n",
    "\n",
    "#### Ecuación / Metodología de Estimación\n",
    "1. **Inicialización:** Crear una población inicial de soluciones.\n",
    "2. **Evaluación:** Evaluar la aptitud de cada solución.\n",
    "3. **Selección:** Seleccionar las soluciones más aptas para reproducirse.\n",
    "4. **Cruzamiento y Mutación:** Generar nuevas soluciones mediante cruzamiento y mutación.\n",
    "5. **Reemplazo:** Reemplazar las soluciones menos aptas con las nuevas soluciones.\n",
    "6. **Iteración:** Repetir hasta la convergencia o alcanzar un número máximo de generaciones.\n",
    "\n",
    "#### Interpretación de Parámetros\n",
    "- Los parámetros representan las soluciones en el espacio de búsqueda y se evolucionan iterativamente para mejorar la aptitud.\n",
    "\n",
    "#### Suposiciones\n",
    "1. La función de aptitud es bien definida y permite comparar soluciones.\n",
    "2. Existe suficiente diversidad en la población inicial para explorar el espacio de soluciones.\n",
    "\n",
    "Cada uno de estos métodos tiene sus propias ventajas y limitaciones, y la elección del método adecuado depende de la naturaleza del problema y las características de los datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Función objetivo\n",
    "def objective(x):\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# Optimización diferencial evolutiva\n",
    "bounds = [(-5.0, 5.0)]\n",
    "result = differential_evolution(objective, bounds, seed=42)\n",
    "x_opt = result.x[0]\n",
    "\n",
    "print(f\"Parámetro optimizado: {x_opt}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
